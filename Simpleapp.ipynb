{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edaa62a1",
   "metadata": {},
   "source": [
    "### Simple Gen AI APP Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d9f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "# langsmith tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2615b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='Prompt engineering concepts - Docs by LangChainSkip to main contentüöÄ Share how you\\'re building agents for a chance to win LangChain swag!Docs by LangChain home pageLangSmithSearch...‚åòKAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationPrompt engineering conceptsGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupOverviewQuickstartConceptsCreate and update promptsCreate a promptManage promptsManage prompts programmaticallyConfigure prompt settingsUse tools in a promptInclude multimodal content in a promptWrite your prompt with AIConnect to modelsTutorialsOptimize a classifierSync prompts with GitHubTest multi-turn conversationsOn this pageWhy prompt engineering?Prompts vs. prompt templatesPrompts in LangSmithChat vs CompletionF-string vs. mustacheToolsStructured outputModelPrompt versioningCommitsTagsPrompt playgroundTesting multiple promptsTesting over a datasetVideo guidePrompt engineering conceptsCopy pageCopy pageWhile traditional software applications are built by writing code, AI applications often derive their logic from prompts.\\nThis guide will walk through the key concepts of prompt engineering in LangSmith.\\n\\u200bWhy prompt engineering?\\nA prompt sets the stage for the model, like an audience member at an improv show directing the actor‚Äôs next performance - it guides the model‚Äôs behavior without changing its underlying capabilities. Just as telling an actor to ‚Äúbe a pirate‚Äù determines how they act, a prompt provides instructions, examples, and context that shape how the model responds.\\nPrompt engineering is important because it allows you to change the way the model behaves. While there are other ways to change the model‚Äôs behavior (like fine-tuning), prompt engineering is usually the simplest to get started with and often provides the highest ROI.\\nWe often see that prompt engineering is multi-disciplinary. Sometimes the best prompt engineer is not the software engineer who is building the application, but rather the product manager or another domain expert. It is important to have the proper tooling and infrastructure to support this cross-disciplinary building.\\n\\u200bPrompts vs. prompt templates\\nAlthough we often use these terms interchangably, it is important to understand the difference between ‚Äúprompts‚Äù and ‚Äúprompt templates‚Äù.\\nPrompts refer to the messages that are passed into the language model.\\nPrompt Templates refer to a way of formatting information to get that prompt to hold the information that you want. Prompt templates can include variables for few shot examples, outside context, or any other external data that is needed in your prompt.\\n\\n\\u200bPrompts in LangSmith\\nYou can store and version prompts templates in LangSmith. There are few key aspects of a prompt template to understand.\\n\\u200bChat vs Completion\\nThere are two different types of prompts: chat style prompts and completion style prompts.\\nChat style prompts are a list of messages. This is the prompting style supported by most model APIs these days, and so this should generally be preferred.\\nCompletion style prompts are just a string. This is an older style of prompting, and so mostly exists for legacy reasons.\\n\\u200bF-string vs. mustache\\nYou can format your prompt with input variables using either f-string or mustache format. Here is an example prompt with f-string format:\\nCopyHello, {name}!\\n\\nAnd here is one with mustache:\\nCopyHello, {{name}}!\\n\\nTo add a conditional mustache prompt:\\nCopy{{#is_logged_in}}  Welcome back, {{name}}!{{else}}  Please log in.{{/is_logged_in}}\\n\\n\\nThe playground UI will pick up is_logged_in variable, but any nested variables you‚Äôll need to specify yourself. Paste the following into inputs to ensure the above conditional prompt works:\\n\\nCopy{  \"name\": \"Alice\"}\\n\\nThe LangSmith Playground uses f-string as the default template format, but you can switch to mustache format in the prompt settings/template format section. mustache gives you more flexibility around conditional variables, loops, and nested keys. For conditional variables, you‚Äôll need to manually add json variables in the ‚Äòinputs‚Äô section. Read the documentation\\n\\u200bTools\\nTools are interfaces the LLM can use to interact with the outside world. Tools consist of a name, description, and JSON schema of arguments used to call the tool.\\n\\u200bStructured output\\nStructured output is a feature of most state of the art LLMs, wherein instead of producing raw text as output they stick to a specified schema. This may or may not use Tools under the hood.\\nStructured output is similar to tools, but different in a few key ways. With tools, the LLM choose which tool to call (or may choose not to call any); with structured output, the LLM always responds in this format. With tools, the LLM may select multiple tools; with structured output, only one response is generate.\\n\\u200bModel\\nOptionally, you can store a model configuration alongside a prompt template. This includes the name of the model and any other parameters (temperature, etc).\\n\\u200bPrompt versioning\\nVerisioning is a key part of iterating and collaborating on your different prompts.\\n\\u200bCommits\\nEvery saved update to a prompt creates a new commit with a unique commit hash. This allows you to:\\n\\nView the full history of changes to a prompt.\\nReview earlier versions.\\nRevert to a previous state if needed.\\nReference specific versions in your code using the commit hash (e.g., client.pull_prompt(\"prompt_name:commit_hash\")).\\n\\nIn the UI, you can compare a commit with its previous version by toggling Show diff in the top-right corner of the Commits tab.\\n\\n\\u200bTags\\nCommit tags are human-readable labels that point to specific commits in your prompt‚Äôs history. Unlike commit hashes, tags can be moved to point to different commits, allowing you to update which version your code references without changing the code itself.\\nUse cases for commit tags can include:\\n\\nEnvironment-specific tags: Mark commits for production or staging environments, which allows you to switch between different versions without changing your code.\\nVersion control: Mark stable versions of your prompts, for example, v1, v2, which lets you reference specific versions in your code and track changes over time.\\nCollaboration: Mark versions ready for review, which enables you to share specific versions with collaborators and get feedback.\\n\\nNot to be confused with resource tags: Commit tags reference specific prompt versions. Resource tags are key-value pairs used to organize workspace resources.\\nFor detailed information on creating and managing commit tags, see Manage prompts.\\n\\u200bPrompt playground\\nThe prompt playground makes the process of iterating and testing your prompts seamless. You can enter the playground from the sidebar or directly from a saved prompt.\\nIn the playground you can:\\n\\nChange the model being used\\nChange prompt template being used\\nChange the output schema\\nChange the tools available\\nEnter the input variables to run through the prompt template\\nRun the prompt through the model\\nObserve the outputs\\n\\n\\u200bTesting multiple prompts\\nYou can add more prompts to your playground to easily compare outputs and decide which version is better:\\n\\n\\u200bTesting over a dataset\\nTo test over a dataset, you simply select the dataset from the top right and press Start. You can modify whether the results are streamed back as well as how many repitions there are in the test.\\n\\nYou can click on the ‚ÄúView Experiment‚Äù button to dive deeper into the results of the test.\\n\\u200bVideo guide\\n\\n\\nEdit the source of this page on GitHub.\\nConnect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoPrompt engineering quickstartPreviousCreate a promptNext‚åòIDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data ingestion - From the website we need to scrape the data\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.langchain.com/langsmith/prompt-engineering-concepts\")\n",
    "docs = loader.load()\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be3ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data --> Docs --> Divide our text into chunks --> text to vectors --> Vector Embedding --> Vectore Store DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b43c0563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content=\"Prompt engineering concepts - Docs by LangChainSkip to main contentüöÄ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangSmithSearch...‚åòKAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationPrompt engineering conceptsGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupOverviewQuickstartConceptsCreate and update promptsCreate a promptManage promptsManage prompts programmaticallyConfigure prompt settingsUse tools in a promptInclude multimodal content in a promptWrite your prompt with AIConnect to modelsTutorialsOptimize a classifierSync prompts with GitHubTest multi-turn conversationsOn this pageWhy prompt engineering?Prompts vs. prompt templatesPrompts in LangSmithChat vs CompletionF-string vs. mustacheToolsStructured outputModelPrompt versioningCommitsTagsPrompt playgroundTesting multiple promptsTesting over a datasetVideo guidePrompt engineering conceptsCopy pageCopy pageWhile traditional software\"),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='outputModelPrompt versioningCommitsTagsPrompt playgroundTesting multiple promptsTesting over a datasetVideo guidePrompt engineering conceptsCopy pageCopy pageWhile traditional software applications are built by writing code, AI applications often derive their logic from prompts.'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='This guide will walk through the key concepts of prompt engineering in LangSmith.\\n\\u200bWhy prompt engineering?\\nA prompt sets the stage for the model, like an audience member at an improv show directing the actor‚Äôs next performance - it guides the model‚Äôs behavior without changing its underlying capabilities. Just as telling an actor to ‚Äúbe a pirate‚Äù determines how they act, a prompt provides instructions, examples, and context that shape how the model responds.\\nPrompt engineering is important because it allows you to change the way the model behaves. While there are other ways to change the model‚Äôs behavior (like fine-tuning), prompt engineering is usually the simplest to get started with and often provides the highest ROI.'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='We often see that prompt engineering is multi-disciplinary. Sometimes the best prompt engineer is not the software engineer who is building the application, but rather the product manager or another domain expert. It is important to have the proper tooling and infrastructure to support this cross-disciplinary building.\\n\\u200bPrompts vs. prompt templates\\nAlthough we often use these terms interchangably, it is important to understand the difference between ‚Äúprompts‚Äù and ‚Äúprompt templates‚Äù.\\nPrompts refer to the messages that are passed into the language model.\\nPrompt Templates refer to a way of formatting information to get that prompt to hold the information that you want. Prompt templates can include variables for few shot examples, outside context, or any other external data that is needed in your prompt.'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='\\u200bPrompts in LangSmith\\nYou can store and version prompts templates in LangSmith. There are few key aspects of a prompt template to understand.\\n\\u200bChat vs Completion\\nThere are two different types of prompts: chat style prompts and completion style prompts.\\nChat style prompts are a list of messages. This is the prompting style supported by most model APIs these days, and so this should generally be preferred.\\nCompletion style prompts are just a string. This is an older style of prompting, and so mostly exists for legacy reasons.\\n\\u200bF-string vs. mustache\\nYou can format your prompt with input variables using either f-string or mustache format. Here is an example prompt with f-string format:\\nCopyHello, {name}!\\n\\nAnd here is one with mustache:\\nCopyHello, {{name}}!\\n\\nTo add a conditional mustache prompt:\\nCopy{{#is_logged_in}}  Welcome back, {{name}}!{{else}}  Please log in.{{/is_logged_in}}'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='And here is one with mustache:\\nCopyHello, {{name}}!\\n\\nTo add a conditional mustache prompt:\\nCopy{{#is_logged_in}}  Welcome back, {{name}}!{{else}}  Please log in.{{/is_logged_in}}\\n\\n\\nThe playground UI will pick up is_logged_in variable, but any nested variables you‚Äôll need to specify yourself. Paste the following into inputs to ensure the above conditional prompt works:\\n\\nCopy{  \"name\": \"Alice\"}'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='The LangSmith Playground uses f-string as the default template format, but you can switch to mustache format in the prompt settings/template format section. mustache gives you more flexibility around conditional variables, loops, and nested keys. For conditional variables, you‚Äôll need to manually add json variables in the ‚Äòinputs‚Äô section. Read the documentation\\n\\u200bTools\\nTools are interfaces the LLM can use to interact with the outside world. Tools consist of a name, description, and JSON schema of arguments used to call the tool.\\n\\u200bStructured output\\nStructured output is a feature of most state of the art LLMs, wherein instead of producing raw text as output they stick to a specified schema. This may or may not use Tools under the hood.'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='Structured output is a feature of most state of the art LLMs, wherein instead of producing raw text as output they stick to a specified schema. This may or may not use Tools under the hood.\\nStructured output is similar to tools, but different in a few key ways. With tools, the LLM choose which tool to call (or may choose not to call any); with structured output, the LLM always responds in this format. With tools, the LLM may select multiple tools; with structured output, only one response is generate.\\n\\u200bModel\\nOptionally, you can store a model configuration alongside a prompt template. This includes the name of the model and any other parameters (temperature, etc).\\n\\u200bPrompt versioning\\nVerisioning is a key part of iterating and collaborating on your different prompts.\\n\\u200bCommits\\nEvery saved update to a prompt creates a new commit with a unique commit hash. This allows you to:'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='View the full history of changes to a prompt.\\nReview earlier versions.\\nRevert to a previous state if needed.\\nReference specific versions in your code using the commit hash (e.g., client.pull_prompt(\"prompt_name:commit_hash\")).\\n\\nIn the UI, you can compare a commit with its previous version by toggling Show diff in the top-right corner of the Commits tab.\\n\\n\\u200bTags\\nCommit tags are human-readable labels that point to specific commits in your prompt‚Äôs history. Unlike commit hashes, tags can be moved to point to different commits, allowing you to update which version your code references without changing the code itself.\\nUse cases for commit tags can include:'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='Environment-specific tags: Mark commits for production or staging environments, which allows you to switch between different versions without changing your code.\\nVersion control: Mark stable versions of your prompts, for example, v1, v2, which lets you reference specific versions in your code and track changes over time.\\nCollaboration: Mark versions ready for review, which enables you to share specific versions with collaborators and get feedback.\\n\\nNot to be confused with resource tags: Commit tags reference specific prompt versions. Resource tags are key-value pairs used to organize workspace resources.\\nFor detailed information on creating and managing commit tags, see Manage prompts.\\n\\u200bPrompt playground\\nThe prompt playground makes the process of iterating and testing your prompts seamless. You can enter the playground from the sidebar or directly from a saved prompt.\\nIn the playground you can:'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='Change the model being used\\nChange prompt template being used\\nChange the output schema\\nChange the tools available\\nEnter the input variables to run through the prompt template\\nRun the prompt through the model\\nObserve the outputs\\n\\n\\u200bTesting multiple prompts\\nYou can add more prompts to your playground to easily compare outputs and decide which version is better:\\n\\n\\u200bTesting over a dataset\\nTo test over a dataset, you simply select the dataset from the top right and press Start. You can modify whether the results are streamed back as well as how many repitions there are in the test.\\n\\nYou can click on the ‚ÄúView Experiment‚Äù button to dive deeper into the results of the test.\\n\\u200bVideo guide'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='You can click on the ‚ÄúView Experiment‚Äù button to dive deeper into the results of the test.\\n\\u200bVideo guide\\n\\n\\nEdit the source of this page on GitHub.\\nConnect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoPrompt engineering quickstartPreviousCreate a promptNext‚åòIDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b860c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings=OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee089d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb=FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62643ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x28235545cc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d426739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputModelPrompt versioningCommitsTagsPrompt playgroundTesting multiple promptsTesting over a datasetVideo guidePrompt engineering conceptsCopy pageCopy pageWhile traditional software applications are built by writing code, AI applications often derive their logic from prompts.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query from a vector db\n",
    "query = \"While traditional software applications are built by writing code, AI applications often derive their logic from prompts.\"\n",
    "result = vectorstoredb.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a083a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f90d9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000028234F04160>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000028235545E70>, root_client=<openai.OpenAI object at 0x0000028234F047C0>, root_async_client=<openai.AsyncOpenAI object at 0x0000028235547760>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieval Chain, Document chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8df8918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI applications often derive their logic from prompts rather than traditional coding according to the provided context.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "     \"input\":\"While traditional software applications are built by writing code, AI applications often derive their logic from prompts.\",\n",
    "     \"context\":[Document(page_content=\"While traditional software applications are built by writing code, AI applications often derive their logic from prompts.This guide will walk through the key concepts of prompt engineering in LangSmith.\")]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f041d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, we want the documents to first come from the retriver we jast set up. That way, we can use the retriver to dynamically select the most relevant documetns and pass those in for a given question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0978faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x28235545cc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retriver\n",
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddaa2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstoredb.as_retriever()\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "retriever_chain=create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67138666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000028235545CC0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000028234F04160>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000028235545E70>, root_client=<openai.OpenAI object at 0x0000028234F047C0>, root_async_client=<openai.AsyncOpenAI object at 0x0000028235547760>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a9f8c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the difference between \"prompts\" and \"prompt templates\"?\\n\\nPrompts refer to the messages that are passed into the language model, while prompt templates refer to a way of formatting information to get that prompt to hold the information you want. Prompt templates can include variables for few shot examples, outside context, or any other external data needed in the prompt.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the resposne from the LLM\n",
    "response=retriever_chain.invoke({\"input\":\"While traditional software applications are built by writing code, AI applications often derive their logic from prompts.\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "323f47e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'While traditional software applications are built by writing code, AI applications often derive their logic from prompts.',\n",
       " 'context': [Document(id='4bb4b107-fcc4-4806-bc84-6e8e17d7a265', metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='outputModelPrompt versioningCommitsTagsPrompt playgroundTesting multiple promptsTesting over a datasetVideo guidePrompt engineering conceptsCopy pageCopy pageWhile traditional software applications are built by writing code, AI applications often derive their logic from prompts.'),\n",
       "  Document(id='dc63a6f4-8f1c-4cce-ba1e-19bac3e09acb', metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='We often see that prompt engineering is multi-disciplinary. Sometimes the best prompt engineer is not the software engineer who is building the application, but rather the product manager or another domain expert. It is important to have the proper tooling and infrastructure to support this cross-disciplinary building.\\n\\u200bPrompts vs. prompt templates\\nAlthough we often use these terms interchangably, it is important to understand the difference between ‚Äúprompts‚Äù and ‚Äúprompt templates‚Äù.\\nPrompts refer to the messages that are passed into the language model.\\nPrompt Templates refer to a way of formatting information to get that prompt to hold the information that you want. Prompt templates can include variables for few shot examples, outside context, or any other external data that is needed in your prompt.'),\n",
       "  Document(id='16c4e8ca-c9d9-47be-9740-206b05d23584', metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content=\"Prompt engineering concepts - Docs by LangChainSkip to main contentüöÄ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangSmithSearch...‚åòKAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationPrompt engineering conceptsGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupOverviewQuickstartConceptsCreate and update promptsCreate a promptManage promptsManage prompts programmaticallyConfigure prompt settingsUse tools in a promptInclude multimodal content in a promptWrite your prompt with AIConnect to modelsTutorialsOptimize a classifierSync prompts with GitHubTest multi-turn conversationsOn this pageWhy prompt engineering?Prompts vs. prompt templatesPrompts in LangSmithChat vs CompletionF-string vs. mustacheToolsStructured outputModelPrompt versioningCommitsTagsPrompt playgroundTesting multiple promptsTesting over a datasetVideo guidePrompt engineering conceptsCopy pageCopy pageWhile traditional software\"),\n",
       "  Document(id='27382c9e-c50c-4e23-b52f-f2ac472253d4', metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='This guide will walk through the key concepts of prompt engineering in LangSmith.\\n\\u200bWhy prompt engineering?\\nA prompt sets the stage for the model, like an audience member at an improv show directing the actor‚Äôs next performance - it guides the model‚Äôs behavior without changing its underlying capabilities. Just as telling an actor to ‚Äúbe a pirate‚Äù determines how they act, a prompt provides instructions, examples, and context that shape how the model responds.\\nPrompt engineering is important because it allows you to change the way the model behaves. While there are other ways to change the model‚Äôs behavior (like fine-tuning), prompt engineering is usually the simplest to get started with and often provides the highest ROI.')],\n",
       " 'answer': 'What is the difference between \"prompts\" and \"prompt templates\"?\\n\\nPrompts refer to the messages that are passed into the language model, while prompt templates refer to a way of formatting information to get that prompt to hold the information you want. Prompt templates can include variables for few shot examples, outside context, or any other external data needed in the prompt.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d8d2d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='4bb4b107-fcc4-4806-bc84-6e8e17d7a265', metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='outputModelPrompt versioningCommitsTagsPrompt playgroundTesting multiple promptsTesting over a datasetVideo guidePrompt engineering conceptsCopy pageCopy pageWhile traditional software applications are built by writing code, AI applications often derive their logic from prompts.'),\n",
       " Document(id='dc63a6f4-8f1c-4cce-ba1e-19bac3e09acb', metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='We often see that prompt engineering is multi-disciplinary. Sometimes the best prompt engineer is not the software engineer who is building the application, but rather the product manager or another domain expert. It is important to have the proper tooling and infrastructure to support this cross-disciplinary building.\\n\\u200bPrompts vs. prompt templates\\nAlthough we often use these terms interchangably, it is important to understand the difference between ‚Äúprompts‚Äù and ‚Äúprompt templates‚Äù.\\nPrompts refer to the messages that are passed into the language model.\\nPrompt Templates refer to a way of formatting information to get that prompt to hold the information that you want. Prompt templates can include variables for few shot examples, outside context, or any other external data that is needed in your prompt.'),\n",
       " Document(id='16c4e8ca-c9d9-47be-9740-206b05d23584', metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content=\"Prompt engineering concepts - Docs by LangChainSkip to main contentüöÄ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangSmithSearch...‚åòKAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationPrompt engineering conceptsGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupOverviewQuickstartConceptsCreate and update promptsCreate a promptManage promptsManage prompts programmaticallyConfigure prompt settingsUse tools in a promptInclude multimodal content in a promptWrite your prompt with AIConnect to modelsTutorialsOptimize a classifierSync prompts with GitHubTest multi-turn conversationsOn this pageWhy prompt engineering?Prompts vs. prompt templatesPrompts in LangSmithChat vs CompletionF-string vs. mustacheToolsStructured outputModelPrompt versioningCommitsTagsPrompt playgroundTesting multiple promptsTesting over a datasetVideo guidePrompt engineering conceptsCopy pageCopy pageWhile traditional software\"),\n",
       " Document(id='27382c9e-c50c-4e23-b52f-f2ac472253d4', metadata={'source': 'https://docs.langchain.com/langsmith/prompt-engineering-concepts', 'title': 'Prompt engineering concepts - Docs by LangChain', 'language': 'en'}, page_content='This guide will walk through the key concepts of prompt engineering in LangSmith.\\n\\u200bWhy prompt engineering?\\nA prompt sets the stage for the model, like an audience member at an improv show directing the actor‚Äôs next performance - it guides the model‚Äôs behavior without changing its underlying capabilities. Just as telling an actor to ‚Äúbe a pirate‚Äù determines how they act, a prompt provides instructions, examples, and context that shape how the model responds.\\nPrompt engineering is important because it allows you to change the way the model behaves. While there are other ways to change the model‚Äôs behavior (like fine-tuning), prompt engineering is usually the simplest to get started with and often provides the highest ROI.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2835f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
