{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017a22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "# langsmith tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300fd342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000211E32A0A00> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211E32A0F10> root_client=<openai.OpenAI object at 0x00000211E32A08B0> root_async_client=<openai.AsyncOpenAI object at 0x00000211E32A0EB0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd7f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"Find this pincode 532312 of which district?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ae124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The pincode 532312 corresponds to a region in the Srikakulam district of Andhra Pradesh, India.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 18, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_672b6a21ba', 'id': 'chatcmpl-Cg6CmbqIaCgeidwDHQBP44pUR0CqA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--473dda44-707e-4bf5-aff0-3235a7963448-0' usage_metadata={'input_tokens': 18, 'output_tokens': 23, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aeee7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chatpropt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answers based on the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49af7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a tool developed by LangChain to help developers build, test, debug, and evaluate language model applications. It offers features that allow developers to deeply understand how their language models are performing, optimize their applications, and enhance their reliability and accuracy.\\n\\nKey capabilities of Langsmith include:\\n\\n1. **Instrumentation**: Helps in observing what's happening within your application in real-time, providing insights into which parts of the application are performing well and which are not.\\n\\n2. **Testing**: Allows developers to create and run test cases for their language model applications to ensure consistent performance across various scenarios.\\n\\n3. **Debugging**: Offers tools to diagnose and fix issues within language model workflows, making it easier to trace errors and unexpected behavior.\\n\\n4. **Evaluation**: Provides metrics and analytics that help developers assess the performance and quality of their models more effectively. This includes understanding aspects like model accuracy, response times, and user satisfaction.\\n\\nBy bridging the gap between development and operations, Langsmith helps streamline the lifecycle of language model applications, making it a valuable asset for developers working with complex LLM-based systems.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 222, 'prompt_tokens': 33, 'total_tokens': 255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ed643dde95', 'id': 'chatcmpl-Cg6OUSt5qzQoB8zDYeqJGITfgL91C', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--849123af-323e-4478-98d4-307bdf7b3b85-0' usage_metadata={'input_tokens': 33, 'output_tokens': 222, 'total_tokens': 255, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# chain\n",
    "chain=prompt|llm\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ce4990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f60ff514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a toolset specifically designed to enhance the development, testing, and monitoring of applications built with large language models. Developed by the creators of LangChain, Langsmith aims to provide developers with more robust tools to improve the quality and reliability of LLM-powered applications. Among its key features are the ability to conduct more detailed evaluations of language model outputs and insights into application performance. By using Langsmith, developers can identify and resolve issues more efficiently, ultimately leading to more effective and reliable language model integrations.\n"
     ]
    }
   ],
   "source": [
    "# stroutput Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe71ff80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
